{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Current device: 0\n",
      "Device: cuda:0\n",
      "Device count: 1\n",
      "Device name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "available = torch.cuda.is_available()\n",
    "curr_device = torch.cuda.current_device()\n",
    "device = torch.device(\"cuda:0\" if available else \"cpu\") \n",
    "device_count = torch.cuda.device_count() \n",
    "device_name =  torch.cuda.get_device_name(0)\n",
    "\n",
    "print(f'Cuda available: {available}')\n",
    "print(f'Current device: {curr_device}')\n",
    "print(f'Device: {device}')\n",
    "print(f'Device count: {device_count}')\n",
    "print(f'Device name: {device_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2043, 0.2169, 0.5543, 1.4761],\n",
       "         [0.8260, 1.1556, 1.0174, 1.5874]],\n",
       "\n",
       "        [[1.8310, 1.7862, 0.7170, 0.3091],\n",
       "         [1.5134, 1.2704, 0.1828, 0.5689]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 2, 4) * 2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3218, -0.3240,  0.0983,  0.0544],\n",
       "         [-0.3228, -0.3258,  0.0981,  0.0494]],\n",
       "\n",
       "        [[-0.3574, -0.2369, -0.2491, -0.1151],\n",
       "         [-0.3571, -0.2377, -0.2487, -0.1162]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelfAttention(4, 2)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0629, -1.5632, -0.1381,  0.6384],\n",
       "         [-0.4127, -1.2894,  0.2517,  1.4504]],\n",
       "\n",
       "        [[ 1.0825,  0.2708,  0.2823, -1.6356],\n",
       "         [ 1.7107, -0.6735, -0.7212, -0.3160]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransformerBlock(4, 2, 8)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjlkeng/devel/cramming/.conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/home/bjlkeng/devel/cramming/.conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 42\n",
      "Found cached dataset glue (/home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1226.64it/s]\n",
      "Loading cached processed dataset at /home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1afe93c2c61c7931.arrow\n",
      "Loading cached processed dataset at /home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1f28bd522d35d185.arrow\n",
      "Loading cached processed dataset at /home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a8f0d4e0f4309ddf.arrow\n",
      "Loading cached processed dataset at /home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1fa1141c31746ea3.arrow\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from src.dataloaders import GLUEDataModule\n",
    "\n",
    "seed_everything(42)\n",
    "dm = GLUEDataModule(model_name_or_path='bert-large-uncased', \n",
    "                    task_name='cola',\n",
    "                    train_batch_size=32,\n",
    "                    eval_batch_size=32)\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class TestModel(LightningModule):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = VanillaBert(**kwargs)\n",
    "        self.training_step_outputs = []\n",
    "\n",
    "        \n",
    "    def forward(self, **kwargs):\n",
    "        return self.model(kwargs['input_ids'])\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(**batch)\n",
    "        loss = F.binary_cross_entropy_with_logits(outputs, batch['labels'].float())\n",
    "        self.training_step_outputs.append(loss)\n",
    "        return loss\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        outputs = self(**batch)\n",
    "        val_loss = F.binary_cross_entropy_with_logits(outputs, batch['labels'].float())\n",
    "        return {'loss': val_loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        '''Prepare optimizer and schedule (linear warmup and decay)'''\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.0001, betas=(0.9, 0.999),)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "VanillaBert() got an unexpected keyword argument 'n_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningModule, Trainer, seed_everything\n\u001b[1;32m      3\u001b[0m seed_everything(\u001b[39m42\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model \u001b[39m=\u001b[39m TestModel(vocab_size\u001b[39m=\u001b[39;49mdm\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mvocab_size, n_layers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# BK: Using val_loss to pick best model for simplicity here\u001b[39;00m\n\u001b[1;32m      8\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      9\u001b[0m     max_epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m     10\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     devices\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m )\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mTestModel.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m      8\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m VanillaBert(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step_outputs \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: VanillaBert() got an unexpected keyword argument 'n_layers'"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "model = TestModel(vocab_size=dm.tokenizer.vocab_size, n_blocks=1)\n",
    "\n",
    "# BK: Using val_loss to pick best model for simplicity here\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator='auto',\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    ")\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35b020ec3df0c18b68bf7b4552e70845f81858dcbaf541b576d2fc743ffe38c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
