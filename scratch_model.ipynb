{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Current device: 0\n",
      "Device: cuda:0\n",
      "Device count: 1\n",
      "Device name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "available = torch.cuda.is_available()\n",
    "curr_device = torch.cuda.current_device()\n",
    "device = torch.device(\"cuda:0\" if available else \"cpu\") \n",
    "device_count = torch.cuda.device_count() \n",
    "device_name =  torch.cuda.get_device_name(0)\n",
    "\n",
    "print(f'Cuda available: {available}')\n",
    "print(f'Current device: {curr_device}')\n",
    "print(f'Device: {device}')\n",
    "print(f'Device count: {device_count}')\n",
    "print(f'Device name: {device_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5975, 0.4855, 1.4737, 0.7699],\n",
       "         [1.7126, 1.7917, 0.1524, 0.2950]],\n",
       "\n",
       "        [[1.2589, 1.3450, 0.1758, 1.2254],\n",
       "         [0.8413, 1.1939, 1.7003, 1.3048]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 2, 4) * 2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3609, -0.1882, -0.2390, -0.0220],\n",
       "         [-0.3520, -0.1843, -0.2294, -0.0346]],\n",
       "\n",
       "        [[-0.2381, -0.2981, -0.2113, -0.2449],\n",
       "         [-0.2330, -0.2940, -0.2039, -0.2541]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelfAttention(4, 2)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0400, -1.0413, -0.9570,  0.9583],\n",
       "         [ 0.4257,  0.9135, -1.6912,  0.3521]],\n",
       "\n",
       "        [[-0.0557,  0.6907, -1.6055,  0.9706],\n",
       "         [-1.1947,  0.9214, -0.7816,  1.0549]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransformerBlock(4, 2, 8)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjlkeng/devel/cramming/.conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/home/bjlkeng/devel/cramming/.conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 42\n",
      "Found cached dataset glue (/home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 379.54it/s]\n",
      "Loading cached processed dataset at /home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1afe93c2c61c7931.arrow\n",
      "Loading cached processed dataset at /home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1f28bd522d35d185.arrow\n",
      "Loading cached processed dataset at /home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a8f0d4e0f4309ddf.arrow\n",
      "Loading cached processed dataset at /home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1fa1141c31746ea3.arrow\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from src.dataloaders import GLUEDataModule\n",
    "\n",
    "seed_everything(42)\n",
    "dm = GLUEDataModule(model_name_or_path='bert-large-uncased', \n",
    "                    task_name='cola',\n",
    "                    train_batch_size=32,\n",
    "                    eval_batch_size=32)\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class TestModel(LightningModule):\n",
    "    def __init__(self, adamw_params=None, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = VanillaBert(**kwargs)\n",
    "        self.adamw_params = adamw_params\n",
    "        \n",
    "    def forward(self, **kwargs):\n",
    "        return self.model(kwargs['input_ids'])\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(**batch)\n",
    "        loss = F.binary_cross_entropy_with_logits(outputs, batch['labels'].float())\n",
    "        return loss\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        outputs = self(**batch)\n",
    "        val_loss = F.binary_cross_entropy_with_logits(outputs, batch['labels'].float())\n",
    "        return {'loss': val_loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        '''Prepare optimizer and schedule (linear warmup and decay)'''\n",
    "        adamw_params = {\n",
    "            'lr': 0.0001, \n",
    "            'betas': (0.9, 0.98), \n",
    "            'eps': 10e-12,\n",
    "            'weight_decay': 0.01,\n",
    "        }\n",
    "        if self.adamw_params:\n",
    "            adamw_params.update(self.adamw_params)\n",
    "        optimizer = optim.AdamW(self.model.parameters(), **adamw_params)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Found cached dataset glue (/home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1344.47it/s]\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Found cached dataset glue (/home/bjlkeng/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1199.17it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | TransformerModule | 30.5 M\n",
      "--------------------------------------------\n",
      "30.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.5 M    Total params\n",
      "122.115   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 301/301 [00:04<00:00, 61.49it/s, loss=0.532, v_num=37, val_loss=0.659, train_loss=0.528]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 301/301 [00:05<00:00, 57.01it/s, loss=0.532, v_num=37, val_loss=0.659, train_loss=0.528]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "adamw_params = {\n",
    "    'lr': 0.0001,\n",
    "    'betas': (0.9, 0.999),\n",
    "    'eps': 10e-8,\n",
    "    'weight_decay': 0.01,\n",
    "}\n",
    "model = TestModel(vocab_size=dm.tokenizer.vocab_size, \n",
    "                  n_blocks=1,\n",
    "                  adamw_params=adamw_params,)\n",
    "\n",
    "# BK: Using val_loss to pick best model for simplicity here\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator='auto',\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    ")\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35b020ec3df0c18b68bf7b4552e70845f81858dcbaf541b576d2fc743ffe38c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
