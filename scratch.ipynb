{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjlkeng/devel/cramming/.conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from src.dataloaders import CoLADataModule\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Current device: 0\n",
      "Device: cuda:0\n",
      "Device count: 1\n",
      "Device name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "available = torch.cuda.is_available()\n",
    "curr_device = torch.cuda.current_device()\n",
    "device = torch.device(\"cuda:0\" if available else \"cpu\") \n",
    "device_count = torch.cuda.device_count() \n",
    "device_name =  torch.cuda.get_device_name(0)\n",
    "\n",
    "print(f'Cuda available: {available}')\n",
    "print(f'Current device: {curr_device}')\n",
    "print(f'Device: {device}')\n",
    "print(f'Device count: {device_count}')\n",
    "print(f'Device name: {device_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder = SentenceTransformer('all-mpnet-base-v2')\n",
    "dm = CoLADataModule(data_dir='./glue_data/CoLA/', batch_size=1000, sentence_encoder=sentence_encoder)\n",
    "\n",
    "#dm.setup(stage='fit')\n",
    "#dm.setup(stage='validate')\n",
    "#dm.setup(stage='test')\n",
    "#\n",
    "#for i, (x, y) in enumerate(dm.train):\n",
    "#    if i < 10:\n",
    "#        print(f'i: x = {x}, y = {y}')\n",
    "\n",
    "#sentence_encoder.encode(dm.train.x_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LightningModule\n",
    "class CoLAClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(nn.Linear(768, 768), \n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(768, 1),\n",
    "                                     nn.Sigmoid())\n",
    "        self.accuracy = BinaryAccuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.network(x)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, targets = batch\n",
    "        y = self.network(x)\n",
    "        print(x.shape, y.shape)\n",
    "\n",
    "        loss = nn.functional.binary_cross_entropy(y, targets)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, targets = batch\n",
    "        y = self.network(x)\n",
    "        val_loss = nn.functional.binary_cross_entropy(y, targets)\n",
    "        self.log(\"test_accuracy\", self.accuracy(y, targets))\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, targets = batch\n",
    "        y = self.network(x)\n",
    "        metric = BinaryAccuracy()\n",
    "        self.log(\"test_accuracy\", self.accuracy(y, targets))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "cls = CoLAClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/bjlkeng/devel/cramming/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type           | Params\n",
      "--------------------------------------------\n",
      "0 | network  | Sequential     | 591 K \n",
      "1 | accuracy | BinaryAccuracy | 0     \n",
      "--------------------------------------------\n",
      "591 K     Trainable params\n",
      "0         Non-trainable params\n",
      "591 K     Total params\n",
      "2.365     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjlkeng/devel/cramming/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/bjlkeng/devel/cramming/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/bjlkeng/devel/cramming/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 0:   9%|▉         | 1/11 [00:00<00:00, 97.76it/s, loss=0.695, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 0:  18%|█▊        | 2/11 [00:00<00:00, 121.00it/s, loss=0.691, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 0:  27%|██▋       | 3/11 [00:00<00:00, 129.34it/s, loss=0.687, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 0:  36%|███▋      | 4/11 [00:00<00:00, 136.49it/s, loss=0.68, v_num=34] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 0:  45%|████▌     | 5/11 [00:00<00:00, 136.08it/s, loss=0.677, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 0:  55%|█████▍    | 6/11 [00:00<00:00, 134.63it/s, loss=0.67, v_num=34] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 0:  64%|██████▎   | 7/11 [00:00<00:00, 133.25it/s, loss=0.663, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 0:  73%|███████▎  | 8/11 [00:00<00:00, 135.79it/s, loss=0.658, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.656, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 1:   9%|▉         | 1/11 [00:00<00:00, 122.24it/s, loss=0.656, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 1:  18%|█▊        | 2/11 [00:00<00:00, 128.21it/s, loss=0.656, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 1:  27%|██▋       | 3/11 [00:00<00:00, 134.85it/s, loss=0.654, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 1:  36%|███▋      | 4/11 [00:00<00:00, 140.13it/s, loss=0.649, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 1:  45%|████▌     | 5/11 [00:00<00:00, 137.00it/s, loss=0.649, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 1:  55%|█████▍    | 6/11 [00:00<00:00, 138.95it/s, loss=0.643, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 1:  64%|██████▎   | 7/11 [00:00<00:00, 139.52it/s, loss=0.638, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 1:  73%|███████▎  | 8/11 [00:00<00:00, 141.96it/s, loss=0.636, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.635, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 2:   9%|▉         | 1/11 [00:00<00:00, 129.89it/s, loss=0.637, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 2:  18%|█▊        | 2/11 [00:00<00:00, 143.42it/s, loss=0.639, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 2:  27%|██▋       | 3/11 [00:00<00:00, 151.43it/s, loss=0.636, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 2:  36%|███▋      | 4/11 [00:00<00:00, 150.58it/s, loss=0.631, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 2:  45%|████▌     | 5/11 [00:00<00:00, 152.11it/s, loss=0.629, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 2:  55%|█████▍    | 6/11 [00:00<00:00, 151.96it/s, loss=0.624, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 2:  64%|██████▎   | 7/11 [00:00<00:00, 152.05it/s, loss=0.618, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 2:  73%|███████▎  | 8/11 [00:00<00:00, 152.59it/s, loss=0.615, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.615, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 3:   9%|▉         | 1/11 [00:00<00:00, 127.93it/s, loss=0.616, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 3:  18%|█▊        | 2/11 [00:00<00:00, 142.83it/s, loss=0.617, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 3:  27%|██▋       | 3/11 [00:00<00:00, 144.04it/s, loss=0.616, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 3:  36%|███▋      | 4/11 [00:00<00:00, 143.80it/s, loss=0.612, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 3:  45%|████▌     | 5/11 [00:00<00:00, 143.84it/s, loss=0.612, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 3:  55%|█████▍    | 6/11 [00:00<00:00, 142.04it/s, loss=0.61, v_num=34] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 3:  64%|██████▎   | 7/11 [00:00<00:00, 143.05it/s, loss=0.605, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 3:  73%|███████▎  | 8/11 [00:00<00:00, 145.55it/s, loss=0.606, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.608, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 4:   9%|▉         | 1/11 [00:00<00:00, 123.38it/s, loss=0.61, v_num=34] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 4:  18%|█▊        | 2/11 [00:00<00:00, 131.24it/s, loss=0.611, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 4:  27%|██▋       | 3/11 [00:00<00:00, 141.25it/s, loss=0.608, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 4:  36%|███▋      | 4/11 [00:00<00:00, 145.25it/s, loss=0.603, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 4:  45%|████▌     | 5/11 [00:00<00:00, 44.34it/s, loss=0.602, v_num=34] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 4:  55%|█████▍    | 6/11 [00:00<00:00, 50.33it/s, loss=0.6, v_num=34]  torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 4:  64%|██████▎   | 7/11 [00:00<00:00, 55.56it/s, loss=0.595, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 4:  73%|███████▎  | 8/11 [00:00<00:00, 60.39it/s, loss=0.596, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.598, v_num=34]         torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 5:   9%|▉         | 1/11 [00:00<00:00, 122.49it/s, loss=0.601, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 5:  18%|█▊        | 2/11 [00:00<00:00, 142.16it/s, loss=0.603, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 5:  27%|██▋       | 3/11 [00:00<00:00, 146.19it/s, loss=0.601, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 5:  36%|███▋      | 4/11 [00:00<00:00, 147.36it/s, loss=0.596, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 5:  45%|████▌     | 5/11 [00:00<00:00, 147.80it/s, loss=0.596, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 5:  55%|█████▍    | 6/11 [00:00<00:00, 144.03it/s, loss=0.594, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 5:  64%|██████▎   | 7/11 [00:00<00:00, 143.37it/s, loss=0.588, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 5:  73%|███████▎  | 8/11 [00:00<00:00, 144.94it/s, loss=0.589, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.591, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 6:   9%|▉         | 1/11 [00:00<00:00, 133.92it/s, loss=0.593, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 6:  18%|█▊        | 2/11 [00:00<00:00, 144.71it/s, loss=0.595, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 6:  27%|██▋       | 3/11 [00:00<00:00, 151.37it/s, loss=0.593, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 6:  36%|███▋      | 4/11 [00:00<00:00, 154.57it/s, loss=0.588, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 6:  45%|████▌     | 5/11 [00:00<00:00, 158.02it/s, loss=0.588, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 6:  55%|█████▍    | 6/11 [00:00<00:00, 159.79it/s, loss=0.586, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 6:  64%|██████▎   | 7/11 [00:00<00:00, 161.76it/s, loss=0.581, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 6:  73%|███████▎  | 8/11 [00:00<00:00, 162.81it/s, loss=0.581, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.584, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 7:   9%|▉         | 1/11 [00:00<00:00, 131.84it/s, loss=0.586, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 7:  18%|█▊        | 2/11 [00:00<00:00, 135.46it/s, loss=0.589, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 7:  27%|██▋       | 3/11 [00:00<00:00, 141.69it/s, loss=0.586, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 7:  36%|███▋      | 4/11 [00:00<00:00, 146.02it/s, loss=0.581, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 7:  45%|████▌     | 5/11 [00:00<00:00, 148.90it/s, loss=0.581, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 7:  55%|█████▍    | 6/11 [00:00<00:00, 150.74it/s, loss=0.579, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 7:  64%|██████▎   | 7/11 [00:00<00:00, 153.26it/s, loss=0.573, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 7:  73%|███████▎  | 8/11 [00:00<00:00, 153.82it/s, loss=0.574, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.576, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 8:   9%|▉         | 1/11 [00:00<00:00, 124.93it/s, loss=0.579, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 8:  18%|█▊        | 2/11 [00:00<00:00, 133.78it/s, loss=0.582, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 8:  27%|██▋       | 3/11 [00:00<00:00, 134.44it/s, loss=0.579, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 8:  36%|███▋      | 4/11 [00:00<00:00, 141.13it/s, loss=0.573, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 8:  45%|████▌     | 5/11 [00:00<00:00, 146.03it/s, loss=0.574, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 8:  55%|█████▍    | 6/11 [00:00<00:00, 146.30it/s, loss=0.572, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 8:  64%|██████▎   | 7/11 [00:00<00:00, 148.30it/s, loss=0.566, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 8:  73%|███████▎  | 8/11 [00:00<00:00, 148.01it/s, loss=0.567, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.569, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 9:   9%|▉         | 1/11 [00:00<00:00, 133.73it/s, loss=0.572, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 9:  18%|█▊        | 2/11 [00:00<00:00, 141.63it/s, loss=0.575, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 9:  27%|██▋       | 3/11 [00:00<00:00, 142.25it/s, loss=0.572, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 9:  36%|███▋      | 4/11 [00:00<00:00, 146.58it/s, loss=0.566, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 9:  45%|████▌     | 5/11 [00:00<00:00, 150.78it/s, loss=0.567, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 9:  55%|█████▍    | 6/11 [00:00<00:00, 153.64it/s, loss=0.565, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 9:  64%|██████▎   | 7/11 [00:00<00:00, 154.62it/s, loss=0.559, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 9:  73%|███████▎  | 8/11 [00:00<00:00, 155.39it/s, loss=0.56, v_num=34] torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.562, v_num=34]         torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 10:   9%|▉         | 1/11 [00:00<00:00, 133.57it/s, loss=0.565, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 10:  18%|█▊        | 2/11 [00:00<00:00, 145.01it/s, loss=0.568, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 10:  27%|██▋       | 3/11 [00:00<00:00, 148.34it/s, loss=0.565, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 10:  36%|███▋      | 4/11 [00:00<00:00, 149.94it/s, loss=0.559, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 10:  45%|████▌     | 5/11 [00:00<00:00, 151.61it/s, loss=0.56, v_num=34] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 10:  55%|█████▍    | 6/11 [00:00<00:00, 153.16it/s, loss=0.558, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 10:  64%|██████▎   | 7/11 [00:00<00:00, 154.17it/s, loss=0.551, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 10:  73%|███████▎  | 8/11 [00:00<00:00, 155.01it/s, loss=0.552, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.555, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 11:   9%|▉         | 1/11 [00:00<00:00, 121.98it/s, loss=0.558, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 11:  18%|█▊        | 2/11 [00:00<00:00, 141.93it/s, loss=0.561, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 11:  27%|██▋       | 3/11 [00:00<00:00, 143.79it/s, loss=0.558, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 11:  36%|███▋      | 4/11 [00:00<00:00, 147.19it/s, loss=0.552, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 11:  45%|████▌     | 5/11 [00:00<00:00, 149.77it/s, loss=0.553, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 11:  55%|█████▍    | 6/11 [00:00<00:00, 152.57it/s, loss=0.551, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 11:  64%|██████▎   | 7/11 [00:00<00:00, 153.74it/s, loss=0.544, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 11:  73%|███████▎  | 8/11 [00:00<00:00, 154.57it/s, loss=0.545, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.548, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 12:   9%|▉         | 1/11 [00:00<00:00, 140.02it/s, loss=0.551, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 12:  18%|█▊        | 2/11 [00:00<00:00, 151.92it/s, loss=0.554, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 12:  27%|██▋       | 3/11 [00:00<00:00, 150.68it/s, loss=0.551, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 12:  36%|███▋      | 4/11 [00:00<00:00, 155.97it/s, loss=0.545, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 12:  45%|████▌     | 5/11 [00:00<00:00, 155.69it/s, loss=0.546, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 12:  55%|█████▍    | 6/11 [00:00<00:00, 156.43it/s, loss=0.544, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 12:  64%|██████▎   | 7/11 [00:00<00:00, 155.04it/s, loss=0.537, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 12:  73%|███████▎  | 8/11 [00:00<00:00, 155.26it/s, loss=0.538, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.541, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 13:   9%|▉         | 1/11 [00:00<00:00, 133.93it/s, loss=0.544, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 13:  18%|█▊        | 2/11 [00:00<00:00, 147.60it/s, loss=0.547, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 13:  27%|██▋       | 3/11 [00:00<00:00, 148.64it/s, loss=0.544, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 13:  36%|███▋      | 4/11 [00:00<00:00, 151.11it/s, loss=0.538, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 13:  45%|████▌     | 5/11 [00:00<00:00, 151.66it/s, loss=0.539, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 13:  55%|█████▍    | 6/11 [00:00<00:00, 50.24it/s, loss=0.537, v_num=34] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 13:  64%|██████▎   | 7/11 [00:00<00:00, 55.53it/s, loss=0.53, v_num=34] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 13:  73%|███████▎  | 8/11 [00:00<00:00, 60.44it/s, loss=0.531, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.534, v_num=34]         torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 14:   9%|▉         | 1/11 [00:00<00:00, 123.14it/s, loss=0.536, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 14:  18%|█▊        | 2/11 [00:00<00:00, 135.23it/s, loss=0.54, v_num=34] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 14:  27%|██▋       | 3/11 [00:00<00:00, 137.78it/s, loss=0.537, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 14:  36%|███▋      | 4/11 [00:00<00:00, 140.51it/s, loss=0.531, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 14:  45%|████▌     | 5/11 [00:00<00:00, 145.37it/s, loss=0.531, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 14:  55%|█████▍    | 6/11 [00:00<00:00, 146.38it/s, loss=0.53, v_num=34] torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 14:  64%|██████▎   | 7/11 [00:00<00:00, 148.85it/s, loss=0.523, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 14:  73%|███████▎  | 8/11 [00:00<00:00, 150.53it/s, loss=0.524, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.526, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 15:   9%|▉         | 1/11 [00:00<00:00, 134.94it/s, loss=0.529, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 15:  18%|█▊        | 2/11 [00:00<00:00, 149.69it/s, loss=0.533, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 15:  27%|██▋       | 3/11 [00:00<00:00, 154.54it/s, loss=0.529, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 15:  36%|███▋      | 4/11 [00:00<00:00, 158.28it/s, loss=0.523, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 15:  45%|████▌     | 5/11 [00:00<00:00, 159.94it/s, loss=0.524, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 15:  55%|█████▍    | 6/11 [00:00<00:00, 162.07it/s, loss=0.523, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 15:  64%|██████▎   | 7/11 [00:00<00:00, 162.37it/s, loss=0.516, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 15:  73%|███████▎  | 8/11 [00:00<00:00, 161.96it/s, loss=0.517, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.519, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 16:   9%|▉         | 1/11 [00:00<00:00, 139.21it/s, loss=0.522, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 16:  18%|█▊        | 2/11 [00:00<00:00, 150.98it/s, loss=0.526, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 16:  27%|██▋       | 3/11 [00:00<00:00, 151.91it/s, loss=0.522, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 16:  36%|███▋      | 4/11 [00:00<00:00, 153.23it/s, loss=0.516, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 16:  45%|████▌     | 5/11 [00:00<00:00, 153.06it/s, loss=0.517, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 16:  55%|█████▍    | 6/11 [00:00<00:00, 154.91it/s, loss=0.515, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 16:  64%|██████▎   | 7/11 [00:00<00:00, 154.60it/s, loss=0.509, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 16:  73%|███████▎  | 8/11 [00:00<00:00, 154.92it/s, loss=0.51, v_num=34] torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.511, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 17:   9%|▉         | 1/11 [00:00<00:00, 123.16it/s, loss=0.514, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 17:  18%|█▊        | 2/11 [00:00<00:00, 132.04it/s, loss=0.518, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 17:  27%|██▋       | 3/11 [00:00<00:00, 136.86it/s, loss=0.515, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 17:  36%|███▋      | 4/11 [00:00<00:00, 144.05it/s, loss=0.509, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 17:  45%|████▌     | 5/11 [00:00<00:00, 147.08it/s, loss=0.509, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 17:  55%|█████▍    | 6/11 [00:00<00:00, 149.76it/s, loss=0.508, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 17:  64%|██████▎   | 7/11 [00:00<00:00, 146.77it/s, loss=0.502, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 17:  73%|███████▎  | 8/11 [00:00<00:00, 147.05it/s, loss=0.502, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.504, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 18:   9%|▉         | 1/11 [00:00<00:00, 130.51it/s, loss=0.507, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 18:  18%|█▊        | 2/11 [00:00<00:00, 144.19it/s, loss=0.511, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 18:  27%|██▋       | 3/11 [00:00<00:00, 143.89it/s, loss=0.507, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 18:  36%|███▋      | 4/11 [00:00<00:00, 149.03it/s, loss=0.501, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 18:  45%|████▌     | 5/11 [00:00<00:00, 148.82it/s, loss=0.502, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 18:  55%|█████▍    | 6/11 [00:00<00:00, 150.59it/s, loss=0.5, v_num=34]  torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 18:  64%|██████▎   | 7/11 [00:00<00:00, 150.00it/s, loss=0.494, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 18:  73%|███████▎  | 8/11 [00:00<00:00, 149.97it/s, loss=0.494, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s, loss=0.496, v_num=34]          torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 19:   9%|▉         | 1/11 [00:00<00:00, 125.30it/s, loss=0.499, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 19:  18%|█▊        | 2/11 [00:00<00:00, 134.14it/s, loss=0.503, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 19:  27%|██▋       | 3/11 [00:00<00:00, 143.30it/s, loss=0.499, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 19:  36%|███▋      | 4/11 [00:00<00:00, 148.36it/s, loss=0.493, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 19:  45%|████▌     | 5/11 [00:00<00:00, 150.40it/s, loss=0.494, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 19:  55%|█████▍    | 6/11 [00:00<00:00, 150.89it/s, loss=0.492, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 19:  64%|██████▎   | 7/11 [00:00<00:00, 152.72it/s, loss=0.486, v_num=34]torch.Size([1000, 768]) torch.Size([1000, 1])\n",
      "Epoch 19:  73%|███████▎  | 8/11 [00:00<00:00, 153.20it/s, loss=0.486, v_num=34]torch.Size([551, 768]) torch.Size([551, 1])\n",
      "Epoch 19: 100%|██████████| 11/11 [00:00<00:00, 138.58it/s, loss=0.488, v_num=34]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 11/11 [00:00<00:00, 125.55it/s, loss=0.488, v_num=34]\n"
     ]
    }
   ],
   "source": [
    "dm.setup(stage='fit')\n",
    "dm.setup(stage='validate')\n",
    "dm.setup(stage='test')\n",
    "\n",
    "trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=20)\n",
    "trainer.fit(model=cls, datamodule=dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer.predict` requires `forward` method to run.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mpredict(model\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m, datamodule\u001b[39m=\u001b[39;49mdm)\n",
      "File \u001b[0;32m~/devel/cramming/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:892\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    890\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    891\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 892\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    893\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_impl, model, dataloaders, datamodule, return_predictions, ckpt_path\n\u001b[1;32m    894\u001b[0m )\n",
      "File \u001b[0;32m~/devel/cramming/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/devel/cramming/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:938\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    933\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn, ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    934\u001b[0m )\n\u001b[1;32m    936\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predicted_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path  \u001b[39m# TODO: remove in v1.8\u001b[39;00m\n\u001b[0;32m--> 938\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    940\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/devel/cramming/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1038\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector\u001b[39m.\u001b[39m_attach_model_callbacks()\n\u001b[1;32m   1036\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector\u001b[39m.\u001b[39m_attach_model_logging_functions()\n\u001b[0;32m-> 1038\u001b[0m verify_loop_configurations(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1040\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: preparing data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/devel/cramming/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:49\u001b[0m, in \u001b[0;36mverify_loop_configurations\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     __verify_eval_loop_configuration(model, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[39melif\u001b[39;00m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mPREDICTING:\n\u001b[0;32m---> 49\u001b[0m     __verify_eval_loop_configuration(model, \u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     51\u001b[0m __verify_batch_transfer_support(trainer)\n\u001b[1;32m     52\u001b[0m \u001b[39m# TODO: Delete this check in v2.0\u001b[39;00m\n",
      "File \u001b[0;32m~/devel/cramming/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:125\u001b[0m, in \u001b[0;36m__verify_eval_loop_configuration\u001b[0;34m(model, stage)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39m`predict_step` cannot be None to run `Trainer.predict`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_step \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_overridden(\u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m, model):\n\u001b[0;32m--> 125\u001b[0m         \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39m`Trainer.predict` requires `forward` method to run.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[39m# -----------------------------------\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[39m# verify model has an eval_step\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[39m# -----------------------------------\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_step:\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer.predict` requires `forward` method to run."
     ]
    }
   ],
   "source": [
    "trainer.predict(model=cls, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35b020ec3df0c18b68bf7b4552e70845f81858dcbaf541b576d2fc743ffe38c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
